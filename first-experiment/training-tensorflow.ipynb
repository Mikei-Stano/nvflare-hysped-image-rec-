{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2999e5e0-beef-4c84-ae4d-22f19b6e1ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "721/721 [==============================] - 1s 924us/step - loss: 2.3999 - accuracy: 0.3093 - val_loss: 2.2628 - val_accuracy: 0.3310\n",
      "Epoch 2/10\n",
      "721/721 [==============================] - 1s 845us/step - loss: 2.1959 - accuracy: 0.3387 - val_loss: 2.1407 - val_accuracy: 0.3426\n",
      "Epoch 3/10\n",
      "721/721 [==============================] - 1s 944us/step - loss: 2.0873 - accuracy: 0.3608 - val_loss: 2.0107 - val_accuracy: 0.3845\n",
      "Epoch 4/10\n",
      "721/721 [==============================] - 1s 843us/step - loss: 2.0254 - accuracy: 0.3724 - val_loss: 1.9772 - val_accuracy: 0.3830\n",
      "Epoch 5/10\n",
      "721/721 [==============================] - 1s 963us/step - loss: 1.9596 - accuracy: 0.3858 - val_loss: 1.9602 - val_accuracy: 0.3847\n",
      "Epoch 6/10\n",
      "721/721 [==============================] - 1s 821us/step - loss: 1.9359 - accuracy: 0.3880 - val_loss: 1.9270 - val_accuracy: 0.3887\n",
      "Epoch 7/10\n",
      "721/721 [==============================] - 1s 933us/step - loss: 1.9060 - accuracy: 0.3958 - val_loss: 1.9075 - val_accuracy: 0.4011\n",
      "Epoch 8/10\n",
      "721/721 [==============================] - 1s 732us/step - loss: 1.8839 - accuracy: 0.4038 - val_loss: 1.8559 - val_accuracy: 0.4063\n",
      "Epoch 9/10\n",
      "721/721 [==============================] - 1s 732us/step - loss: 1.8564 - accuracy: 0.4087 - val_loss: 1.8304 - val_accuracy: 0.4257\n",
      "Epoch 10/10\n",
      "721/721 [==============================] - 1s 730us/step - loss: 1.8304 - accuracy: 0.4184 - val_loss: 1.8397 - val_accuracy: 0.4096\n",
      "Test Loss: 1.8638, Test Accuracy: 0.4006\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"smaller_dataset.csv\")\n",
    "\n",
    "# Preprocess the dataset\n",
    "df_encoded = df.drop(columns=[df.columns[0]])  # Drop the first column\n",
    "X = df_encoded.drop(columns=[\"DRUH_POVR\", \"NAZ_LOKALI\"])  # Features\n",
    "y = df_encoded[\"DRUH_POVR\"]  # Target\n",
    "\n",
    "# Convert features to TensorFlow tensors\n",
    "X_tensor = tf.convert_to_tensor(X.to_numpy(), dtype=tf.float32)\n",
    "\n",
    "# Use TensorFlow StringLookup for label encoding\n",
    "label_lookup = tf.keras.layers.StringLookup(output_mode='int', vocabulary=tf.constant(y.unique()))\n",
    "y_tensor = label_lookup(y) - 1  # Adjust labels to start from 0\n",
    "\n",
    "# Create a TensorFlow Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset_size = len(y_tensor)\n",
    "dataset = dataset.shuffle(buffer_size=dataset_size, seed=42)\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_size = int(0.7 * dataset_size)\n",
    "val_size = int(0.15 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "remaining = dataset.skip(train_size)\n",
    "val_dataset = remaining.take(val_size)\n",
    "test_dataset = remaining.skip(val_size)\n",
    "\n",
    "# Batch the datasets for training, validation, and evaluation\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "# Determine the number of classes for the output layer\n",
    "num_classes = len(label_lookup.get_vocabulary()) - 1  # Adjust for 0-based indexing\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),  # Specify input shape\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax'),  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']  # Add accuracy as a metric\n",
    ")\n",
    "\n",
    "# Train the model with a validation set\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset,  # Include validation set\n",
    "    epochs=10,  # Increased epochs for better training\n",
    "    verbose=1  # Display progress\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cec181c6-cf85-4986-b1d7-adabdf9ae89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32950,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429452c4-b5ae-4053-909e-669d356690d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fec110-90c0-47c7-89cb-64cdccd5c004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
